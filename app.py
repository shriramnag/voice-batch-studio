# Version 0.181.14-release
import os
import gradio as gr
from TTS.api import TTS
import torch
import time
import shutil
from pydub import AudioSegment, effects

# ‡§®‡§ø‡§Ø‡§Æ‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•ç‡§µ‡•Ä‡§ï‡§æ‡§∞ ‡§ï‡§∞‡§®‡§æ
os.environ["COQUI_TOS_AGREED"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ‡§Ü‡§µ‡§æ‡•õ‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§´‡•ã‡§≤‡•ç‡§°‡§∞
VOICE_DIR = "custom_voices"
os.makedirs(VOICE_DIR, exist_ok=True)

# ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•Ä ‡§°‡§ø‡•û‡•â‡§≤‡•ç‡§ü ‡§Ü‡§µ‡§æ‡•õ‡•á‡§Ç (‡§á‡§®‡•ç‡§π‡•á‡§Ç ‡§ê‡§™ ‡§´‡•ã‡§≤‡•ç‡§°‡§∞ ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è)
# ‡§Ö‡§ó‡§∞ ‡§´‡§æ‡§á‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à ‡§§‡•ã ‡§è‡§∞‡§∞ ‡§® ‡§Ü‡§è ‡§á‡§∏‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡•á‡§ï
def get_all_voices():
    voices = [f for f in os.listdir(VOICE_DIR) if f.endswith('.wav')]
    return ["Joanne.wav", "Reginald voice.wav"] + voices

print(f"üöÄ ‡§ü‡§∞‡•ç‡§¨‡•ã ‡§Æ‡•ã‡§° ‡§ö‡§æ‡§≤‡•Ç: {device} | ‡§µ‡§∞‡•ç‡§∂‡§®: 0.181.14")

try:
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
except Exception as e:
    print(f"‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§° ‡§è‡§∞‡§∞: {e}")

# --- ‡§®‡§Ø‡§æ ‡§Ü‡§µ‡§æ‡•õ ‡§∏‡•á‡§µ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§´‡§Ç‡§ï‡•ç‡§∂‡§® ---
def save_new_voice(file):
    if file is None: return gr.update()
    filename = os.path.basename(file.name)
    dest = os.path.join(VOICE_DIR, filename)
    shutil.copy(file.name, dest)
    return gr.update(choices=get_all_voices(), value=filename)

def generate_voice(voice_name, script, emotion, speed, language, remove_silence, voice_enhance):
    if not voice_name or not script:
        return None, "‚ùå ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ü‡§µ‡§æ‡•õ ‡§ö‡•Å‡§®‡•á‡§Ç ‡§î‡§∞ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§°‡§æ‡§≤‡•á‡§Ç!"
    
    # ‡§∏‡§π‡•Ä ‡§∞‡§æ‡§∏‡•ç‡§§‡§æ (Path) ‡§ö‡•Å‡§®‡§®‡§æ
    if voice_name in ["Joanne.wav", "Reginald voice.wav"]:
        voice_path = voice_name # ‡§Ø‡•á ‡§´‡§æ‡§á‡§≤‡•á‡§Ç ‡§Æ‡•á‡§® ‡§´‡•ã‡§≤‡•ç‡§°‡§∞ ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è
    else:
        voice_path = os.path.join(VOICE_DIR, voice_name)

    if not os.path.exists(voice_path):
        return None, f"‚ùå ‡§Ü‡§µ‡§æ‡•õ ‡§´‡§æ‡§á‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä: {voice_name}"

    clean_text = script.replace("\n", " ").strip()
    output_path = f"vbs_output_{int(time.time())}.wav"
    
    try:
        tts.tts_to_file(
            text=clean_text,
            speaker_wav=voice_path,
            language=language,
            file_path=output_path,
            emotion=emotion,
            speed=speed,
            enable_text_splitting=True
        )
        
        # ‡§Ü‡§µ‡§æ‡•õ ‡§®‡§ø‡§ñ‡§æ‡§∞‡§®‡§æ ‡§î‡§∞ ‡§∏‡§®‡•ç‡§®‡§æ‡§ü‡§æ ‡§π‡§ü‡§æ‡§®‡§æ
        audio = AudioSegment.from_wav(output_path)
        if remove_silence: audio = effects.strip_silence(audio, silence_thresh=-45, padding=150)
        if voice_enhance: audio = effects.normalize(audio)
        audio.export(output_path, format="wav")
        
        return output_path, "‚úÖ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§∏‡§´‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à!"
    except Exception as e:
        return None, f"‚ùå AI Error: {str(e)}"

# --- ‡§á‡§Ç‡§ü‡§∞‡•û‡•á‡§∏ ---
with gr.Blocks(theme=gr.themes.Soft(primary_hue="green")) as demo:
    gr.Markdown("# üéôÔ∏è **VoiceBatch Studio Pro v0.181.14**")
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ‚öôÔ∏è **‡§µ‡•â‡§Ø‡§∏ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ**")
            
            # ‡§Ü‡§µ‡§æ‡•õ ‡§ö‡•Å‡§®‡§®‡•á ‡§ï‡•Ä ‡§≤‡§ø‡§∏‡•ç‡§ü
            voice_select = gr.Dropdown(choices=get_all_voices(), label="‡§Æ‡•å‡§ú‡•Ç‡§¶‡§æ ‡§Ü‡§µ‡§æ‡•õ ‡§ö‡•Å‡§®‡•á‡§Ç", value="Joanne.wav")
            
            # ‡§®‡§à ‡§Ü‡§µ‡§æ‡•õ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§¨‡§ü‡§® (‡§ú‡•ã ‡§≤‡§æ‡§á‡§¨‡•ç‡§∞‡•á‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ ‡§π‡•ã ‡§ú‡§æ‡§è‡§ó‡•Ä)
            new_voice_upload = gr.File(label="‡§®‡§à ‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•ã ‡§≤‡§æ‡§á‡§¨‡•ç‡§∞‡•á‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡•ã‡•ú‡•á‡§Ç", file_types=[".wav"])
            new_voice_upload.change(save_new_voice, inputs=[new_voice_upload], outputs=[voice_select])

            with gr.Row():
                lang_opt = gr.Dropdown(choices=["hi", "en"], value="hi", label="üåç ‡§≠‡§æ‡§∑‡§æ")
                emotion_opt = gr.Dropdown(choices=["Neutral", "Sad", "Happy", "Angry", "Excited"], value="Neutral", label="üé≠ ‡§á‡§Æ‡•ã‡§∂‡§®")
            
            speed_sl = gr.Slider(0.7, 1.4, 1.0, step=0.01, label="‚è© ‡§∏‡•ç‡§™‡•Ä‡§°")
            silence_btn = gr.Checkbox(label="ü§´ ‡§∏‡§®‡•ç‡§®‡§æ‡§ü‡§æ ‡§π‡§ü‡§æ‡§®‡§æ", value=True)
            enhance_btn = gr.Checkbox(label="‚ú® ‡§Ü‡§µ‡§æ‡•õ ‡§®‡§ø‡§ñ‡§æ‡§∞‡§®‡§æ", value=True)
            
            gen_btn = gr.Button("üöÄ GENERATE AUDIO", variant="primary")
            status = gr.Textbox(label="‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡•ç‡§ü‡•á‡§ü‡§∏", interactive=False)

        with gr.Column(scale=2):
            word_counter = gr.Markdown("‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: 0 / 10,000")
            script_in = gr.Textbox(label="‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§¨‡•â‡§ï‡•ç‡§∏", lines=18)
            script_in.change(lambda x: f"‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: {len(x.split())} / 10,000", inputs=[script_in], outputs=[word_counter])
            
            audio_out = gr.Audio(label="‡§´‡§æ‡§á‡§®‡§≤ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü", type="filepath")

    gen_btn.click(generate_voice, [voice_select, script_in, emotion_opt, speed_sl, lang_opt, silence_btn, enhance_btn], [audio_out, status])

demo.launch(share=True)
